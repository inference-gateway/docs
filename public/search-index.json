{"10":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"15":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"20":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"30":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"40":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"50":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"70":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"80":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"200":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"333":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"1000":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"8080":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"1741879542":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"api":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"reference":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"base":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"url":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"authentication":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"endpoints":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"list":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"all":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"models":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"provider":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"chat":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"completions":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"request":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"body":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"streaming":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"response":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"proxy":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"requests":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"example":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"openai":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"completion":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"health":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"check":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"error":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"responses":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"advanced":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"features":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"tool":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"use":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"direct":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"openapi":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"specification":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"inference":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"gateway":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"provides":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"restful":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"for":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"interacting":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"with":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"language":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"from":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"various":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"providers":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"this":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"documents":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"available":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"formats":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"and":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"structures":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"are":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"relative":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"to":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"your":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"installation":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"by":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"default":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"is":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"http":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"localhost":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"when":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"running":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"locally":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"if":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"enabled":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"enable_authtrue":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"must":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"include":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"bearer":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"token":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"authorization":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"your_jwt_token":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"the":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"jwt":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"issued":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"configured":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"identity":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"idp":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"as":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"specified":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"in":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"openid":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"connect":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"settings":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"oidc_issuer_url":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"oidc_client_id":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"etc":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"validates":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"these":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"tokens":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"against":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"authenticate":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"get":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"of":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"across":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"v1models":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"status":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"ok":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"contenttype":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"applicationjson":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"object":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"data":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"id":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"gpt4":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"model":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"created":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"owned_by":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"served_by":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"claude3opus20240229":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"anthropic":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"meta":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"groq":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"specific":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"v1modelsprovider":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"where":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"one":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"cohere":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"cloudflare":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"ollama":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"deepseek":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"gpt3":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"5turbo":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"using":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"post":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"json":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"ollamadeepseekr1":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"5b":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"name":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"messages":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"array":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"conversation":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"role":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"system":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"user":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"assistant":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"message":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"sender":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"content":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"hi":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"how":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"you":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"doing":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"today":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"stream":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"false":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"optional":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"they":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"re":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"generated":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"max_tokens":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"maximum":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"number":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"generate":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"tools":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"can":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"type":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"function":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"string":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"description":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"parameters":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"schema":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"defining":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"chatcmpl753":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"deepseekr1":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"choices":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"index":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"thinknokay":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"so":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"greeted":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"me":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"said":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"just":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"starting":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"say":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"that":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"should":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"respond":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"friendly":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"way":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"nnmaybe":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"acknowledge":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"their":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"greeting":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"offer":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"my":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"help":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"something":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"since":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"mentioned":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"working":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"on":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"math":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"problems":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"or":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"solving":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"puzzles":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"ll":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"stick":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"nni":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"want":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"make":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"sure":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"approaching":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"it":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"right":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"not":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"question":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"yet":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"but":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"see":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"more":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"them":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"maybe":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"assistance":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"responding":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"an":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"emoji":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"like":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"would":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"be":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"nice":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"nthinknnhello":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"finish_reason":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"length":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"usage":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"prompt_tokens":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"completion_tokens":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"total_tokens":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"true":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"streamed":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"server":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"sent":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"events":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"sse":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"https":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"developer":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"mozilla":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"objects":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"}],"curl":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"helpful":[{"title":"API Reference","excerpt":"Inference Gateway provides a RESTful API for interacting with language models from various providers.","url":"/api-reference"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"architecture":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"overview":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"general":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"kubernetes":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"setup":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"document":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"highlevel":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"inferencegateway":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"designed":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"modular":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"extensible":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"allowing":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"easy":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"integration":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"new":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"mermaid":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"init":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"theme":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"themevariables":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"primarycolor":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"326ce5":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"primarytextcolor":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"fff":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"linecolor":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"5d8aa8":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"secondarycolor":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"006100":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"fontfamily":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"arial":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"flowchart":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"nodespacing":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"rankspacing":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"padding":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"graph":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"td":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"client":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"nodes":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"clients":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"agents":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"v1chatcompletions":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"auth":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"node":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"oidc":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"ig1":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ig2":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ig3":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"h1":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"h2":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"h3":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"define":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"styles":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"classdef":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"fill":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"9370db":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"stroke":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"strokewidth":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"1px":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"color":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"white":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"f5a800":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"black":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"32cd32":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"apply":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"class":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"run":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"following":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"diagram":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"shows":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"external":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"ingress":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"border":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"subgraph":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"cluster":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"ingressapi":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"service":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"internal":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"internalclients":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"internalagents":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"discovery":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pod1":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pod2":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pod3":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pods":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pod":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pg1":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"end":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pg2":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"pg3":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"monitoring":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"stack":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"servicemonitor":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"metrics":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"sm":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"scrapes":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"prometheus":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"grafana":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"connection":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"externalproviders":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"placed":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"inside":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"k8s":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"visually":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"separate":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"ext1":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ext2":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ext3":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ext4":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ext5":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ext6":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ext7":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"ffffff":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"externalsvc":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"monitor":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"84a392":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"internalclient":[{"title":"Architecture Overview","excerpt":"This document provides a high-level overview of the architecture of the Inference Gateway. The Inference-Gateway is designed to be modular and extensible, allowing easy integration of new models and providers.","url":"/architecture-overview"}],"configuration":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"environment":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"variables":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"configmaps":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"secrets":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"configmap":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"secret":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"flexible":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"options":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"adapt":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"needs":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"page":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"covers":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"methods":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"which":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"recommended":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"approach":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"deployment":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"different":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"environments":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"application_name":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"application":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"production":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"enable_telemetry":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"enable":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"telemetry":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"enable_auth":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"configure":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"issuer":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"keycloak":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"oidc_client_secret":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"server_host":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"host":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"server_port":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"port":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"server_read_timeout":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"read":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"timeout":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"30s":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"server_write_timeout":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"write":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"server_idle_timeout":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"idle":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"120s":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"server_tls_cert_path":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"tls":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"certificate":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"path":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"server_tls_key_path":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"client_timeout":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"connections":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"per":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"minimum":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"version":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"tls12":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"access":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"llm":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"anthropic_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"comv1":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"anthropic_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"cloudflare_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"cloudflare_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"cohere_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"com":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"cohere_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"groq_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"comopenaiv1":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"groq_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"ollama_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"8080v1":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"ollama_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"openai_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"openai_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"deepseek_api_url":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"deepseek_api_key":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"deploying":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"nonsensitive":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"keys":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"other":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"sensitive":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"information":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"yaml":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"apiversion":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"v1":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"kind":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"metadata":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"opaque":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"base64encodedkey":[{"title":"Configuration","excerpt":"Inference Gateway provides flexible configuration options to adapt to your specific needs.","url":"/configuration"}],"helm":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"prerequisites":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"upgrading":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"uninstalling":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"chart":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"source":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"guide":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"explains":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"deploy":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"official":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"installed":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"v3":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"kubectl":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"install":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"directly":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"oci":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"registry":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"bash":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"myrelease":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"ghcr":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"namespace":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"createnamespace":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"configurations":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"show":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"values":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"upgrade":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"existing":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"completely":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"remove":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"uninstall":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"delete":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"}],"at":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"github":[{"title":"Deployment with Helm","excerpt":"This guide explains how to deploy the Inference Gateway using the official Helm chart.","url":"/deployment"},{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"examples":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"docker":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"compose":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"basic":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"create":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"scenarios":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"simple":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"set":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"up":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"minimal":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"services":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"image":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"latest":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"ports":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"repository":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"appsv1":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"spec":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"replicas":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"selector":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"matchlabels":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"app":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"template":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"labels":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"containers":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"containerport":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"env":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"valuefrom":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"secretkeyref":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"llmsecrets":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"openaiapikey":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"complete":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"including":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"visit":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"openaigpt4":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"explain":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"works":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"compare":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"contrast":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"detailed":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"cases":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"out":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"full":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"directory":[{"title":"Examples","excerpt":"This page provides examples of how to use Inference Gateway in various scenarios and environments.","url":"/examples"}],"getting":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"started":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"learn":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"pull":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"rm":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"checkout":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"send":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"}],"hello":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"world":[{"title":"Getting Started","excerpt":"Learn how to install and set up Inference Gateway.","url":"/getting-started"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"integrated":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"development":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"ides":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"vscode":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"cursor":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"fully":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"openaicompatible":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"favorite":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"extensions":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"standard":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"sections":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"provide":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"instructions":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"configuring":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"popular":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"continue":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"dev":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"extension":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"supports":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"apis":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"follows":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"marketplace":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"visualstudio":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"continuedev":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"open":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"file":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"command":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"add":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"endpoint":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"title":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"yourmodelname":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"apibase":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"apikey":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"yourapikey":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"save":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"restart":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"sh":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"aifirst":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"code":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"editor":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"go":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"clicking":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"gear":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"icon":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"bottom":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"left":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"corner":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"keyboard":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"shortcut":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"cmd":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"mac":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"ctrl":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"windowslinux":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"sidebar":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"select":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"ai":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"scroll":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"down":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"find":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"custom":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"section":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"toggle":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"enter":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"click":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"changes":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"now":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"will":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"operations":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"aipowered":[{"title":"Integrated Development Environments (IDEs)","excerpt":"Inference Gateway is fully OpenAI-compatible, allowing you to configure it with your favorite IDEs and extensions using standard OpenAI integration settings. The following sections provide instructions for configuring popular IDEs and extensions.","url":"/ides"}],"documentation":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"community":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"main":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"import":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"link":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"nextlink":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"facilitate":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"allows":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"users":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"interact":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"through":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"unified":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"interface":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"simplifying":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"process":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"sending":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"receiving":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"multiple":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"llms":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"enabling":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"mixture":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"experts":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"under":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"mit":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"license":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"easily":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"urls":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"tooluse":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"support":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"calling":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"capabilities":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"supported":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"realtime":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"ready":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"opentelemetry":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"analyze":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"performance":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"built":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"mind":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"configurable":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"timeouts":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"lightweight":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"includes":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"only":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"essential":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"libraries":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"runtime":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"resulting":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"smaller":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"size":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"binary":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"8mb":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"resource":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"consumption":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"consume":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"resources":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"have":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"lower":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"footprint":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"well":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"documented":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"guides":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"tested":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"extensively":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"unit":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"tests":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"maintained":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"actively":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"developed":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"scalable":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"used":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"distributed":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"hpa":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"compliance":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"privacy":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"project":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"does":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"collect":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"analytics":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"ensuring":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"selfhosted":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"control":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"over":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"try":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"follow":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"our":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"href":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"gettingstarted":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"guidelink":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"own":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"instance":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"minutes":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"acts":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"intermediary":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"between":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"applications":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"standardizing":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"interactions":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"single":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"switch":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"without":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"changing":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"implement":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"sophisticated":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"routing":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"fallback":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"mechanisms":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"centralize":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"management":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"security":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"policies":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"opensource":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"growing":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"contributions":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"welcome":[{"title":"Inference Gateway Documentation","excerpt":"Inference Gateway is a proxy server designed to facilitate access to various","url":"/"}],"observability":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"collection":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"components":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"implementation":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"prebuilt":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"dashboards":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"logging":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"robust":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"troubleshoot":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"tracing":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"integrate":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"builtin":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"traces":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"logs":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"insights":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"into":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"behavior":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"variable":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"enable_telemetrytrue":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"exposes":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"scraped":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"count":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"duration":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"rates":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"utilization":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"cpu":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"memory":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"deployments":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"comprehensive":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"exposing":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"timeseries":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"database":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"storing":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"visualization":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"platform":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"discover":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"scrape":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"coreos":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"interval":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"15s":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"namespaceselector":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"matchnames":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"visualize":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"collected":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"volume":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"latency":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"providerspecific":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"types":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"imported":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"outputs":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"structured":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"format":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"analyzed":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"elasticsearch":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"loki":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"log":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"systems":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"setting":[{"title":"Observability","excerpt":"Inference Gateway provides robust observability features to help monitor and troubleshoot your deployment. These features include metrics collection, tracing, and logging capabilities that integrate with popular monitoring tools.","url":"/observability"}],"software":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"kits":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"sdks":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"sdk":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"programming":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"languages":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"simplify":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"typed":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"interfaces":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"handling":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"convenience":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"currently":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"div":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"classname":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"grid":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"gridcols1":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"md":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"gridcols2":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"gap4":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"mb8":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"p4":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"roundedmd":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3pythonh3":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"python":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"stronginstallation":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"strong":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"pip":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"stronggithub":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"strongpypi":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"pypi":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"h3typescripth3":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"typescript":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"},{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"npm":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"inferencegatewaysdk":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"strongnpm":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"www":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"npmjs":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"h3goh3":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"h3rusth3":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"rust":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"cargo":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"strongcrate":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"io":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"crates":[{"title":"Software Development Kits (SDK's)","excerpt":"Inference Gateway provides official SDKs for various programming languages to simplify integration with your applications. These SDKs offer typed interfaces, error handling, and convenience methods for interacting with the Inference Gateway API.","url":"/sdks"}],"details":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"each":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3openaih3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"paccess":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"gpt":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"tokenp":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"pstrongdefault":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"comv1p":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3deepseekh3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"puse":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"natural":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"tasks":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"comp":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3anthropich3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"pconnect":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"claude":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"highquality":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"conversational":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"xheaderp":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3cohereh3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3groqh3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"highperformance":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"lpuaccelerated":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"comopenaiv1p":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3cloudflareh3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"workers":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"comclientv4accountsp":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"textsm":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"account_id":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"aip":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"h3ollamah3":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"prun":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"none":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"8080v1p":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"requires":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"provider_api_url":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"provider_api_key":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"replace":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"uppercase":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"offers":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"two":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"approaches":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"consistent":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"model_name":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"also":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"native":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"8080v1models":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"deepseekreasoner":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"what":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"capital":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"france":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"quantum":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"computing":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"terms":[{"title":"Supported Providers","excerpt":"Inference Gateway provides a unified interface to interact with multiple LLM providers.","url":"/supported-providers"}],"ui":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"selection":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"screenshots":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"roadmap":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"webbased":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"interactively":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"testing":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"exploring":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"userfriendly":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"test":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"experiment":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"view":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"writing":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"any":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"uses":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"backend":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"once":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"ve":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"selected":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"choose":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"offered":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"automatically":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"filters":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"based":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"familiar":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"experience":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"prompt":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"input":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"area":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"markdown":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"formatting":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"interactive":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"reasoning":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"thought":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"statistics":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"clean":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"modern":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"design":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"light":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"dark":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"mode":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"layout":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"responsive":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"desktop":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"mobile":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"devices":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"imageschatui":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"png":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"web":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"technologies":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"nextjs":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"react":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"component":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"structure":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"safety":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"tailwind":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"css":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"styling":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"deployed":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"standalone":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"container":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"could":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"orchestration":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"such":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"self":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"building":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"provided":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"approx":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"300mb":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"js":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"extensive":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"being":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"improved":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"future":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"may":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"mcps":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"context":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"protocol":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"history":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"plugged":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"known":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"databases":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"choice":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"additional":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"customize":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}],"extend":[{"title":"User Interface (UI)","excerpt":"Inference Gateway includes an optional web-based user interface for interactively testing and exploring the various language model providers and capabilities.","url":"/ui"}]}